# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from geopy.distance import geodesic
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from imblearn.over_sampling import SMOTE
import joblib
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

# Streamlit sayfa ayarÄ±
st.set_page_config(layout="wide", page_title="Deprem Analizi UygulamasÄ±")

# Veri yÃ¼kleme fonksiyonu
@st.cache_data
def load_data():
    try:
        df = pd.read_csv("deprem_verisi.csv", encoding='utf-8-sig')
    except:
        df = pd.DataFrame(data)
        df['Log_BÃ¼yÃ¼klÃ¼k'] = np.log10(df['BÃ¼yÃ¼klÃ¼k'] + 0.1)
    return df

# Veri Ã¶n iÅŸleme fonksiyonlarÄ±
def preprocess_data(df):
    # BÃ¼yÃ¼klÃ¼k sÄ±nÄ±flarÄ±
    df['BÃ¼yÃ¼klÃ¼k_SÄ±nÄ±fÄ±'] = pd.cut(df['BÃ¼yÃ¼klÃ¼k'],
                                  bins=[0, 3, 5, 10],
                                  labels=['KÃ¼Ã§Ã¼k', 'Orta', 'BÃ¼yÃ¼k'])
    
    # Log dÃ¶nÃ¼ÅŸÃ¼mÃ¼ ve standardizasyon
    df['Log_BÃ¼yÃ¼klÃ¼k'] = np.log10(df['BÃ¼yÃ¼klÃ¼k'] + 0.1)
    scaler = StandardScaler()
    df['Log_BÃ¼yÃ¼klÃ¼k_Std'] = scaler.fit_transform(df[['Log_BÃ¼yÃ¼klÃ¼k']])
    
    # Tarih Ã¶zellikleri
    df['OluÅŸ ZamanÄ±'] = pd.to_datetime(df['OluÅŸ ZamanÄ±'])
    df['Saat'] = df['OluÅŸ ZamanÄ±'].dt.hour
    df['HaftanÄ±n GÃ¼nÃ¼'] = df['OluÅŸ ZamanÄ±'].dt.dayofweek
    
    return df

# ArtÃ§Ä± ÅŸok tespit fonksiyonu
def label_aftershocks(df, mainshock_mag_threshold=6.0, time_window_days=7, distance_km=50):
    df = df.sort_values("OluÅŸ ZamanÄ±").reset_index(drop=True)
    df['is_aftershock'] = 0
    
    for i, row in df.iterrows():
        if row['BÃ¼yÃ¼klÃ¼k'] >= mainshock_mag_threshold:
            mainshock_time = row['OluÅŸ ZamanÄ±']
            mainshock_loc = (row['Enlem'], row['Boylam'])

            time_window = (df['OluÅŸ ZamanÄ±'] > mainshock_time) & \
                          (df['OluÅŸ ZamanÄ±'] <= mainshock_time + pd.Timedelta(days=time_window_days))

            for j in df[time_window].index:
                aftershock_loc = (df.loc[j, 'Enlem'], df.loc[j, 'Boylam'])
                distance = geodesic(mainshock_loc, aftershock_loc).km

                if distance <= distance_km and df.loc[j, 'BÃ¼yÃ¼klÃ¼k'] < row['BÃ¼yÃ¼klÃ¼k']:
                    df.at[j, 'is_aftershock'] = 1
    return df

# Grafik oluÅŸturma fonksiyonlarÄ±
def create_histograms(df):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    
    sns.histplot(df['BÃ¼yÃ¼klÃ¼k'], bins=30, kde=True, ax=ax1)
    ax1.set_title('Orijinal BÃ¼yÃ¼klÃ¼k DaÄŸÄ±lÄ±mÄ±')
    
    sns.histplot(df['Log_BÃ¼yÃ¼klÃ¼k'], bins=30, kde=True, ax=ax2)
    ax2.set_title('Log10 DÃ¶nÃ¼ÅŸÃ¼mlÃ¼ DaÄŸÄ±lÄ±m')
    
    fig.subplots_adjust(left=0.1, right=0.95, top=0.9, bottom=0.15, wspace=0.25)
    return fig

def create_violin_plots(df):
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
    
    sns.violinplot(x=df['BÃ¼yÃ¼klÃ¼k'], color='lightblue', ax=ax1)
    ax1.set_title('Orijinal BÃ¼yÃ¼klÃ¼k DaÄŸÄ±lÄ±mÄ±')
    
    sns.violinplot(x=df['Log_BÃ¼yÃ¼klÃ¼k'], color='lightgreen', ax=ax2)
    ax2.set_title('Log10 DÃ¶nÃ¼ÅŸÃ¼mlÃ¼ DaÄŸÄ±lÄ±m')
    
    sns.ecdfplot(data=df, x='BÃ¼yÃ¼klÃ¼k', complementary=True, ax=ax3)
    ax3.set_yscale('log')
    ax3.set_title('KÃ¼mÃ¼latif DaÄŸÄ±lÄ±m')
    
    fig.subplots_adjust(left=0.05, right=0.95, top=0.85, bottom=0.15, wspace=0.3)
    return fig

# Model eÄŸitimi fonksiyonlarÄ±
def train_models(X_train, y_train, X_test, y_test):
    modeller = {
        "Random Forest": RandomForestClassifier(random_state=42, class_weight='balanced'),
        "XGBoost": XGBClassifier(random_state=42, scale_pos_weight=12),
        "LightGBM": LGBMClassifier(random_state=42, class_weight='balanced')
    }
    
    results = {}
    for isim, model in modeller.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        results[isim] = {
            'accuracy': accuracy_score(y_test, y_pred),
            'report': classification_report(y_test, y_pred, output_dict=True)
        }
    
    return results

# Streamlit arayÃ¼zÃ¼
def main():
    st.title("ğŸ‡¹ğŸ‡· TÃ¼rkiye Deprem Analizi UygulamasÄ±")
    
    # Veri yÃ¼kleme
    df = load_data()
    df = preprocess_data(df)
    
    # Sidebar
    st.sidebar.header("Analiz Parametreleri")
    min_magnitude = st.sidebar.slider("Minimum BÃ¼yÃ¼klÃ¼k", 2.0, 7.0, 3.0)
    filtered_df = df[df['BÃ¼yÃ¼klÃ¼k'] >= min_magnitude]
    
    # Ana sayfa
    tab1, tab2, tab3 = st.tabs(["Veri Analizi", "GÃ¶rselleÅŸtirme", "Makine Ã–ÄŸrenmesi"])
    
    with tab1:
        st.header("Veri Ã–zeti")
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("### Ä°lk 5 KayÄ±t")
            st.dataframe(filtered_df.head())
            
        with col2:
            st.write("### Temel Ä°statistikler")
            st.dataframe(filtered_df.describe())
        
        st.write(f"### Toplam KayÄ±t SayÄ±sÄ±: {len(filtered_df)}")
    
    with tab2:
        st.header("Veri GÃ¶rselleÅŸtirme")
        
        st.write("### BÃ¼yÃ¼klÃ¼k DaÄŸÄ±lÄ±mlarÄ±")
        try:
            st.pyplot(create_histograms(filtered_df))
        except Exception as e:
            st.error(f"Grafik oluÅŸturma hatasÄ±: {str(e)}")
        
        st.write("### DetaylÄ± DaÄŸÄ±lÄ±m Analizi")
        try:
            st.pyplot(create_violin_plots(filtered_df))
        except Exception as e:
            st.error(f"Grafik oluÅŸturma hatasÄ±: {str(e)}")
        
        # Harita gÃ¶rselleÅŸtirme
        st.write("### Depremlerin CoÄŸrafi DaÄŸÄ±lÄ±mÄ±")
        try:
            st.map(filtered_df[['Enlem', 'Boylam']].rename(columns={'Enlem': 'lat', 'Boylam': 'lon'}))
        except Exception as e:
            st.error(f"Harita oluÅŸturma hatasÄ±: {str(e)}")
    
    with tab3:
        st.header("Makine Ã–ÄŸrenmesi Analizleri")
        
        # ArtÃ§Ä± ÅŸok tespiti
        st.write("### ArtÃ§Ä± Åok Tahmini")
        if st.button("ArtÃ§Ä± ÅoklarÄ± Ä°ÅŸaretle"):
            with st.spinner("ArtÃ§Ä± ÅŸoklar iÅŸaretleniyor..."):
                df = label_aftershocks(df)
                st.success("ArtÃ§Ä± ÅŸoklar baÅŸarÄ±yla iÅŸaretlendi!")
                st.write(df['is_aftershock'].value_counts())
        
        # Model eÄŸitimi
        if 'is_aftershock' in df.columns:
            st.write("#### Model EÄŸitimi")
            ozellikler = ['BÃ¼yÃ¼klÃ¼k', 'Derinlik', 'Saat', 'HaftanÄ±n GÃ¼nÃ¼']
            X = df[ozellikler]
            y = df['is_aftershock']
            
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y)
            
            # SMOTE uygulama
            smote = SMOTE(random_state=42)
            X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
            
            if st.button("Modelleri EÄŸit"):
                with st.spinner("Modeller eÄŸitiliyor..."):
                    results = train_models(X_train_resampled, y_train_resampled, X_test, y_test)
                    
                    for model_name, result in results.items():
                        st.write(f"#### {model_name} SonuÃ§larÄ±")
                        st.write(f"DoÄŸruluk: {result['accuracy']:.2f}")
                        st.dataframe(pd.DataFrame(result['report']).transpose())
        
        # Model kaydetme
        st.write("#### Model Kaydetme")
        if st.button("XGBoost Modelini Kaydet"):
            try:
                xgb = XGBClassifier(random_state=42)
                xgb.fit(X_train_resampled, y_train_resampled)
                joblib.dump(xgb, 'xgboost_model.pkl')
                st.success("Model baÅŸarÄ±yla kaydedildi!")
            except Exception as e:
                st.error(f"Model kaydetme hatasÄ±: {str(e)}")

if __name__ == "__main__":
    main()
    plt.close('all')
